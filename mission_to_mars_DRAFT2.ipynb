{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NASA MARS NEWS\n",
    "# Scrape Nasa Mars News Site & collect latest NEWS TITLE and PARAGRAPH TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nasa_mars_headline_func(browser):   \n",
    "    executable_path = {'executable_path': 'chromedriver'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    # Navigate chromebrowser window to NASA News site\n",
    "    nasa_url = \"https://mars.nasa.gov/news/\"\n",
    "    browser.visit(nasa_url)\n",
    "    # Set a manual delay.\n",
    "    sleep(2) \n",
    "    # &run BeautifulSoup to parse the site's HTML\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Get the latest headline\n",
    "    nasa_title = soup.find_all(\"div\", class_=\"content_title\")[1].get_text()\n",
    "    return nasa_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nasa_mars_para_func(browser):\n",
    "    executable_path = {'executable_path': 'chromedriver'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    nasa_url = \"https://mars.nasa.gov/news/\"\n",
    "    browser.visit(nasa_url)\n",
    "    # Set a manual delay.\n",
    "    sleep(2) \n",
    "    # &run BeautifulSoup to parse the site's HTML\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Get the latest paragraph\n",
    "    nasa_paragraph = soup.find_all(\"div\", class_=\"article_teaser_body\")[0].get_text()\n",
    "    return nasa_paragraph\n",
    "\n",
    "    # Close the chromebrowser window\n",
    "    browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##JPL MARS SPACE IMAGES\n",
    "#Use splinter to find current FEATURED MARS IMAGE\n",
    "# Open a new chrome browser window (and icon on task bar)\n",
    "# uses chromedriver, not chrome\n",
    "def jpl_mars_images_func(browser):\n",
    "    executable_path = {'executable_path': 'chromedriver'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    # Navigate chromebrowser window to JPL images site\n",
    "    jpl_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    browser.visit(jpl_url)\n",
    "    # Set a manual delay.\n",
    "    sleep(2)\n",
    "    # USE SPLINTER to navigate & store jpg url:\n",
    "    # Click on the FULL IMAGE link (in browser)\n",
    "    browser.links.find_by_partial_text(\"FULL IMAGE\").click()\n",
    "    # Set a manual delay.\n",
    "    sleep(3) \n",
    "    # Click on the MORE INFO link (in browser)\n",
    "    browser.links.find_by_partial_text(\"more info\").click()\n",
    "    # Click on the JPEG image (in browser)\n",
    "    browser.links.find_by_partial_text(\".jpg\").click()\n",
    "    # Save a variable of the URL of the JPEG image file \n",
    "    featured_image_url = browser.url\n",
    "    return featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Mars Facts!\n",
    "\n",
    "# use pandas to scrape Mars Data table (facts and structure)\n",
    "# include 9 items: Equatorial Diameter, Polar diameter, mass,\n",
    "# moons, orbit , orbit, surface temp, first record, recorded by\n",
    "\n",
    "def mars_facts_func(browser):\n",
    "    executable_path = {'executable_path': 'chromedriver'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    # Define URL  (Mars Facts)\n",
    "    facts_url = \"https://space-facts.com/mars/\"\n",
    "    # Read in data table via Pandas. \n",
    "    # >> Specify [0] position to get just Mars data \n",
    "    facts_df = pd.read_html(facts_url)[0]\n",
    "    # Create a polished dataframe with column headers and text clean-up\n",
    "    facts_df.columns = [\"Metric\", \"Planet Mars\"]\n",
    "    # Remove the colon character in DESCRIPTION column\n",
    "    facts_df[\"Metric\"] = facts_df[\"Metric\"].str.replace(\":\",\"\") \n",
    "    #display facts_df (for reference)\n",
    "    facts_df\n",
    "    # Use Pandas to convert the data to a HTML table string\n",
    "    facts_df.set_index(\"Metric\", inplace=True)\n",
    "    # print(facts_html)\n",
    "    facts_html = facts_df.to_html()\n",
    "    #return something useable for html later\n",
    "    return facts_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OVERVIEW: MARS HEMISPHERES\n",
    "#  1. Visit USGS Astrogeology site & obtain hi res images for each of Mars' hemispheres\n",
    "#  2. Click each link to open image url to full resolution\n",
    "#  3. Save image url for full res image, and hemisphere tilte containing hemi. name. \n",
    "#   >> use a python dictionary to store the data using the keys \"img_url\" and \"title\"\n",
    "#  4. Append the dictionary with the image url string and the hemisphere title to a list.\n",
    "#     This list will contain one dictionary for each hemisphere\n",
    "\n",
    "# MARS HEMISPHERES, step-by-step\n",
    "#  Visit USGS Astrogeology site & obstain hi res images for each of Mars' hemispheres\n",
    "\n",
    "def mars_hemi_func(browswer):\n",
    "    executable_path = {'executable_path': 'chromedriver'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    \n",
    "# Navigate chromebrowser window to MARS HEMISPHERES website    \n",
    "    mars_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "    browser.visit(mars_url)\n",
    "    # Set a manual delay.\n",
    "    sleep(2) \n",
    "    # &run BeautifulSoup to parse the site's HTML\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Create dictionary for URLs & pics (empty); Create list for image URLs (empty); \n",
    "    # Create list of hemisphere names (FILLED)\n",
    "    mars_dict = {}\n",
    "    mars_hemi_urls = []\n",
    "    mars_hemi = [\"Cerberus\", \"Schiaparelli\", \"Syrtis\", \"Valles\"]\n",
    "    # Loop through hemispheres by name, populate dictionary with URL and pic\n",
    "    for hemi in mars_hemi:\n",
    "        print(hemi)\n",
    "        sleep(3)\n",
    "        browser.links.find_by_partial_text(hemi).click()\n",
    "\n",
    "        face_html = browser.html\n",
    "        soup = BeautifulSoup(face_html, \"html.parser\")\n",
    "        \n",
    "        mars_dict[\"title\"]= soup.find(\n",
    "            \"h2\").get_text().replace(\"Enhanced\",\"\").strip()\n",
    "        mars_dict[\"img_url\"] = soup.find_all(\"div\", class_=\"downloads\")[0].find_all(\"a\")[0][\"href\"]\n",
    "        mars_hemi_urls.append(mars_dict) \n",
    "\n",
    "    # go back to main directory\n",
    "        browser.back()\n",
    "\n",
    "    # print(mars_hemi_urls)\n",
    "    return mars_hemi_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get everything going\n",
    "##SET UP SCRAPE FUNCTION\n",
    "def scrape():\n",
    "    executable_path = {'executable_path': 'chromedriver'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    #Establish the dictionary\n",
    "    mars_scrape_dict = {}\n",
    "    mars_scrape_dict['nasa_title'] = nasa_mars_headline_func(browser)\n",
    "    mars_scrape_dict['nasa_paragraph']= nasa_mars_para_func(browser)\n",
    "    mars_scrape_dict['featured_image_url']= jpl_mars_images_func(browser)\n",
    "    mars_scrape_dict['facts_html']=mars_facts_func(browser)\n",
    "    mars_scrape_dict['mars_urls']=mars_hemi_func(browser)\n",
    "    print(mars_scrape_dict)\n",
    "    browser.quit()\n",
    "    return mars_scrape_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mars_scrape_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0f7557fb13fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmars_scrape_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mars_scrape_dict' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
